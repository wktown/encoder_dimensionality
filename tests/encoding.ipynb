{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import brainscore.benchmarks as bench\n",
    "from brainscore.metrics.regression import linear_regression, ridge_regression\n",
    "#from bonnerlab_brainscore.benchmarks.object2vec import Object2VecEncoderBenchmark\n",
    "from model_tools.activations.pca import LayerPCA\n",
    "from model_tools.brain_transformation.neural import LayerScores\n",
    "from activation_models.generators import get_activation_models\n",
    "from custom_model_tools.hooks import GlobalMaxPool2d, GlobalAvgPool2d, RandomSpatial\n",
    "from utils import timed, id_to_properties\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "for model, layers in get_activation_models():\n",
    "    layers_scores = ridge_encoder()\n",
    "    score = scores.append(layer_scores)\n",
    "scores.to_csv(f'results/encoding_Eig-OLS|benchmark:{benchmark._identifier}|pooling:{pooling}.csv')\n",
    "\n",
    "def ridge_encoder():\n",
    "    \n",
    "\n",
    "\n",
    "@timed\n",
    "def main(benchmark, pooling, debug=False):\n",
    "    save_path = f'results/encoding_Eig-OLS|benchmark:{benchmark._identifier}|pooling:{pooling}.csv'\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'Results already exists: {save_path}')\n",
    "        return\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    for model, layers in get_activation_models():\n",
    "        layer_scores = fit_encoder(benchmark, model, layers, pooling)\n",
    "        scores = scores.append(layer_scores)\n",
    "        if debug:\n",
    "            break\n",
    "    if not debug:\n",
    "        scores.to_csv(save_path, index=False)\n",
    "\n",
    "\n",
    "def fit_encoder(benchmark, model, layers, pooling, hooks=None):\n",
    "    \"\"\"Fit layers one at a time to save on memory\"\"\"\n",
    "\n",
    "    layer_scores = pd.DataFrame()\n",
    "    model_identifier = model.identifier\n",
    "    model_properties = id_to_properties(model_identifier)\n",
    "    \n",
    "    for layer in layers:\n",
    "        if pooling == 'max':\n",
    "            handle = GlobalMaxPool2d.hook(model)\n",
    "            model.identifier = model_identifier + f'|lyr:{layer}|pooling:max'\n",
    "        elif pooling == 'avg':\n",
    "            handle = GlobalAvgPool2d.hook(model)\n",
    "            model.identifier = model_identifier + f'|layer:{layer}|pooling:avg'\n",
    "        elif pooling == 'random_spatial':\n",
    "            handle = RandomSpatial.hook(model)\n",
    "            model.identifier = model_identifier + f'|layer:{layer}|pooling:random_spatial'\n",
    "        elif pooling == 'none':\n",
    "            handle = LayerPCA.hook(model, n_components=1000)\n",
    "            model.identifier = model_identifier + f'|layer:{layer}|pooling:none|n_components:1000'\n",
    "        \n",
    "\n",
    "        handles = []\n",
    "        if hooks is not None:\n",
    "            handles = [cls.hook(model) for cls in hooks]\n",
    "            \n",
    "        logging.info(model.identifier)\n",
    "        logging.info(layer)\n",
    "        model_scores = LayerScores(model_identifier=model.identifier,\n",
    "                                   activations_model=model,\n",
    "                                   visual_degrees=8)\n",
    "        score = model_scores(benchmark=benchmark, layers=[layer], prerun=True)\n",
    "        handle.remove()\n",
    "\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        if 'aggregation' in score.dims:\n",
    "            score = score.to_dataframe(name='').unstack(level='aggregation').reset_index()\n",
    "            score.columns = ['layer', 'score', 'score_error']\n",
    "        else:\n",
    "            score = score.to_dataframe(name='').reset_index()\n",
    "            score.columns = ['layer', 'score']\n",
    "\n",
    "        layer_scores = layer_scores.append(score)\n",
    "\n",
    "    layer_scores = layer_scores.assign(**model_properties)\n",
    "    return layer_scores\n",
    "\n",
    "\n",
    "def get_benchmark(benchmark, region, regression, data_dir):\n",
    "    if benchmark == 'majajhong2015':\n",
    "        assert region in ['IT', 'V4']\n",
    "        identifier = f'dicarlo.MajajHong2015public.{region}-pls'\n",
    "        benchmark = bench.load(identifier)\n",
    "        if regression == 'lin':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'lin')\n",
    "            benchmark._similarity_metric.regression = linear_regression()\n",
    "            #benchmark._similarity_metric.regression._regression.alpha = 0.1\n",
    "        elif regression == 'l2':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'l2')\n",
    "            benchmark._similarity_metric.regression = ridge_regression()\n",
    "    elif benchmark == 'freeman2013':\n",
    "        assert region == 'V1'\n",
    "        identifier = f'movshon.FreemanZiemba2013public.{region}-pls'\n",
    "        benchmark = bench.load(identifier)\n",
    "        if regression == 'lin':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'lin')\n",
    "            benchmark._similarity_metric.regression = linear_regression()\n",
    "            benchmark._similarity_metric.regression._regression.alpha = 0.1\n",
    "        elif regression == 'l2':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'l2')\n",
    "            benchmark._similarity_metric.regression = ridge_regression()\n",
    "    elif benchmark == 'object2vec':\n",
    "        if region == 'all':\n",
    "            region = None\n",
    "        regions = region if region is None or ',' not in region else region.split(',')\n",
    "        #benchmark = Object2VecEncoderBenchmark(data_dir=data_dir, regions=regions, regression=regression)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown benchmark: {benchmark}')\n",
    "    return benchmark\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Fit encoding models to a neural dataset')\n",
    "    parser.add_argument('--bench', type=str, default='majajhong2015',\n",
    "                        choices=['majajhong2015', 'freeman2013', 'object2vec'],\n",
    "                        help='Neural benchmark dataset to fit')\n",
    "    parser.add_argument('--region', type=str, default='IT',\n",
    "                        help='Region(s) to fit. Valid region(s) depend on the neural benchmark')\n",
    "    parser.add_argument('--regression', type=str, default='pls',\n",
    "                        choices=['pls', 'lin', 'l2'],\n",
    "                        help='Partial-least-squares or ordinary-least-squares for fitting')\n",
    "    parser.add_argument('--data_dir', type=str, default=None,\n",
    "                        help='Data directory for neural benchmark (only required for \"object2vec\")')\n",
    "    parser.add_argument('--pooling', dest='pooling', type=str,\n",
    "                        choices=['max','avg','none', 'random_spatial'],\n",
    "                        help='Choose global max-pooling, global avg-pooling, no pooling, or random spatial positions prior to fitting')\n",
    "    parser.add_argument('--debug', action='store_true',\n",
    "                        help='Just run a single model to make sure there are no errors')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    benchmark = get_benchmark(benchmark=args.bench, region=args.region,\n",
    "                              regression=args.regression, data_dir=args.data_dir)\n",
    "    main(benchmark=benchmark, pooling=args.pooling, debug=args.debug)\n",
    "\n",
    "#pooling\n",
    "#fit_encoding_models.py def fit_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/wtownle1/dimensionality_powerlaw/activation_models/AtlasNet/'\n",
    "import sys\n",
    "sys.path.append(p)\n",
    "from activation_models.AtlasNet.model_2L import EngineeredModel2L\n",
    "\n",
    "model = EngineeredModel2L.Build(filters_2=1000)\n",
    "\n",
    "images = 1 #load dicarlo.hvm-public\n",
    "\n",
    "#X = dataset.iloc[:, 2:-1].values\n",
    "X = model(images)\n",
    "#y = dataset. iloc [:, 1].values\n",
    "y = 2 #load neural responses (assy_dicarlo_MajajHOng2015)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>background_id</th>\n",
       "      <th>s</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>filename</th>\n",
       "      <th>rxy</th>\n",
       "      <th>tz</th>\n",
       "      <th>category_name</th>\n",
       "      <th>rxz_semantic</th>\n",
       "      <th>ty</th>\n",
       "      <th>ryz</th>\n",
       "      <th>object_name</th>\n",
       "      <th>variation</th>\n",
       "      <th>size</th>\n",
       "      <th>rxy_semantic</th>\n",
       "      <th>ryz_semantic</th>\n",
       "      <th>rxz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>642</td>\n",
       "      <td>9edd70d8418078fbb25cca46e88d5436983a265f</td>\n",
       "      <td>1.295714</td>\n",
       "      <td>c41c369d7cde564cdb841d66c69cd8ffe025dc12</td>\n",
       "      <td>Pear_obj_rx-92.621_ry-00.595_rz-17.488_tx-00.2...</td>\n",
       "      <td>Pear_obj_rx-92.621_ry-00.595_rz-17.488_tx-00.2...</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>-2.620859</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-16.892377</td>\n",
       "      <td>pear</td>\n",
       "      <td>3</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>-16.892377</td>\n",
       "      <td>-2.620859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             background_id         s  \\\n",
       "641  642  9edd70d8418078fbb25cca46e88d5436983a265f  1.295714   \n",
       "\n",
       "                                     image_id  \\\n",
       "641  c41c369d7cde564cdb841d66c69cd8ffe025dc12   \n",
       "\n",
       "                                       image_file_name  \\\n",
       "641  Pear_obj_rx-92.621_ry-00.595_rz-17.488_tx-00.2...   \n",
       "\n",
       "                                              filename       rxy     tz  \\\n",
       "641  Pear_obj_rx-92.621_ry-00.595_rz-17.488_tx-00.2...  0.027237 -0.599   \n",
       "\n",
       "    category_name  rxz_semantic     ty        ryz object_name  variation  \\\n",
       "641        Fruits     -2.620859 -0.213 -16.892377        pear          3   \n",
       "\n",
       "      size  rxy_semantic  ryz_semantic       rxz  \n",
       "641  256.0      0.027237    -16.892377 -2.620859  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "majaj_csv = pd.read_csv('/data/shared/brainio/brain-score/image_dicarlo_hvm-public.csv')\n",
    "majaj_csv[majaj_csv['image_file_name'] == \"Pear_obj_rx-92.621_ry-00.595_rz-17.488_tx-00.213_ty-00.599_s+00.907_9edd70d8418078fbb25cca46e88d5436983a265f_256x256.png\"]\n",
    "#image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACAQUES = {0: \"Chabo\", 1: \"Tito\"}\n",
    "\n",
    "\n",
    "def open_majajhong_assembly(macaque: int, roi: str) -> xr.DataArray:\n",
    "    assembly = DataAssembly(xr.open_dataarray(MH_PATH))\n",
    "    assembly = average_repetition(assembly)\n",
    "    assembly = (\n",
    "        assembly.rename(\"data\")\n",
    "        .assign_attrs(\n",
    "            {\n",
    "                \"time_bin\": (\n",
    "                    assembly[\"time_bin_start\"].values[0],\n",
    "                    assembly[\"time_bin_end\"].values[0],\n",
    "                ),\n",
    "                \"animal\": MACAQUES[macaque],\n",
    "            }\n",
    "        )\n",
    "        .isel(time_bin=0, drop=True)\n",
    "        .isel({\"neuroid\": assembly[\"animal\"].values == MACAQUES[macaque]})\n",
    "    )\n",
    "    assembly = assembly.isel({\"neuroid\": assembly[\"region\"].values == roi}).transpose(\n",
    "        \"presentation\", \"neuroid\"\n",
    "    )\n",
    "    return assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading catalog from entrypoints\n",
      "Loading lookup from /home/wtownle1/.conda/envs/encoder-dimensionality/lib/python3.7/site-packages/brainscore/lookup.csv\n",
      "<brainscore.utils.LazyLoad object at 0x7f79d9d18290>\n"
     ]
    }
   ],
   "source": [
    "#def update_by_email(email=None, **kwargs):\n",
    "#    print(kwargs)\n",
    "\n",
    "\n",
    "p = '/home/wtownle1/encoder_dimensionality/'\n",
    "import sys\n",
    "sys.path.append(p)\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import brainscore.benchmarks as bench\n",
    "from brainscore.metrics.regression import linear_regression, ridge_regression\n",
    "#from bonnerlab_brainscore.benchmarks.object2vec import Object2VecEncoderBenchmark\n",
    "from model_tools.activations.pca import LayerPCA\n",
    "from model_tools.brain_transformation.neural import LayerScores\n",
    "from activation_models.generators import get_activation_models\n",
    "from custom_model_tools.hooks import GlobalMaxPool2d #, GlobalAvgPool2d, RandomSpatial\n",
    "from utils import timed, id_to_properties\n",
    "import logging\n",
    "\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "def get_benchmark(benchmark, region, regression, data_dir):\n",
    "    if benchmark == 'majajhong2015':\n",
    "        assert region in ['IT', 'V4']\n",
    "        identifier = f'dicarlo.MajajHong2015public.{region}-pls'\n",
    "        benchmark = bench.load(identifier)\n",
    "        if regression == 'lin':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'lin')\n",
    "            benchmark._similarity_metric.regression = linear_regression()\n",
    "            #benchmark._similarity_metric.regression._regression.alpha = 0.1\n",
    "        elif regression == 'l2':\n",
    "            alpha = 1\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', f'ridge_alpha={alpha}')\n",
    "            benchmark._similarity_metric.regression = ridge_regression(sklearn_kwargs = {'alpha':alpha})\n",
    "            benchmark._similarity_metric.regression = ridge_regression()\n",
    "    elif benchmark == 'freeman2013':\n",
    "        assert region == 'V1'\n",
    "        identifier = f'movshon.FreemanZiemba2013public.{region}-pls'\n",
    "        benchmark = bench.load(identifier)\n",
    "        if regression == 'lin':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'lin')\n",
    "            benchmark._similarity_metric.regression = linear_regression()\n",
    "            benchmark._similarity_metric.regression._regression.alpha = 0.1\n",
    "        elif regression == 'l2':\n",
    "            benchmark._identifier = benchmark.identifier.replace('pls', 'l2')\n",
    "            benchmark._similarity_metric.regression = ridge_regression()\n",
    "    elif benchmark == 'object2vec':\n",
    "        if region == 'all':\n",
    "            region = None\n",
    "        regions = region if region is None or ',' not in region else region.split(',')\n",
    "        #benchmark = Object2VecEncoderBenchmark(data_dir=data_dir, regions=regions, regression=regression)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown benchmark: {benchmark}')\n",
    "    return benchmark\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    parser = argparse.ArgumentParser(description='Fit encoding models to a neural dataset')\n",
    "#    parser.add_argument('--bench', type=str, default='majajhong2015',\n",
    "#                        choices=['majajhong2015', 'freeman2013', 'object2vec'],\n",
    "#                        help='Neural benchmark dataset to fit')\n",
    "#    parser.add_argument('--region', type=str, default='IT',\n",
    "#                        help='Region(s) to fit. Valid region(s) depend on the neural benchmark')\n",
    "#    parser.add_argument('--regression', type=str, default='pls',\n",
    "#                        choices=['pls', 'lin', 'l2'],\n",
    "#                        help='Partial-least-squares or ordinary-least-squares for fitting')\n",
    "#    parser.add_argument('--data_dir', type=str, default=None,\n",
    "#                        help='Data directory for neural benchmark (only required for \"object2vec\")')\n",
    "#    parser.add_argument('--pooling', dest='pooling', type=str,\n",
    "#                        choices=['max','avg','none', 'random_spatial'],\n",
    "#                        help='Choose global max-pooling, global avg-pooling, no pooling, or random spatial positions prior to fitting')\n",
    "#    parser.add_argument('--debug', action='store_true',\n",
    "#                        help='Just run a single model to make sure there are no errors')\n",
    "#    args = parser.parse_args()\n",
    "#\n",
    "\n",
    "benchmark = get_benchmark(benchmark='majajhong2015', region='IT', regression='l2', data_dir=None)\n",
    "#main(benchmark=benchmark, pooling=args.pooling, debug=args.debug)\n",
    "\n",
    "print(benchmark.identifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(benchmark._similarity_metric.regression._regression.alpha)\n",
    "benchmark._identifier = benchmark.identifier.replace('pls', f'ridge_alpha={alpha}')\n",
    "                benchmark._similarity_metric.regression = ridge_regression(sklearn_kwargs = {'alpha':alpha})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_regression(regression_kwargs=None, xarray_kwargs=None):\n",
    "    regression_defaults = dict(n_components=25, scale=False)\n",
    "    regression_kwargs = {**regression_defaults, **(regression_kwargs or {})}\n",
    "    regression = PLSRegression(**regression_kwargs)\n",
    "    xarray_kwargs = xarray_kwargs or {}\n",
    "    regression = XarrayRegression(regression, **xarray_kwargs)\n",
    "    return regression\n",
    "\n",
    "def ridge_regression(regression_kwargs=None, xarray_kwargs=None):\n",
    "    regression_kwargs = regression_kwargs or {}\n",
    "    regression = Ridge(**regression_kwargs)\n",
    "    xarray_kwargs = xarray_kwargs or {}\n",
    "    regression = XarrayRegression(regression, **xarray_kwargs)\n",
    "    return regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encoder-dimensionality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
